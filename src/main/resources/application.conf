hadoop.security.authentication = "kerberos"

hbase {
  zookeeper.property.clientPort = 2181
  zookeeper.quorum = "localhost"
  mapreduce.bulkload.max.hfiles.perRegion.perFamily = 500
}

spark.sql.broadcastTimeout= 2400

app {

  environment = "local"
  debug = "false"

  zookeeper {
    host = "localhost:2181"
    resultFormat = "11%07d"
    path = "/ids/enterprise/id"
    sessionTimeout = 5
    ConnectionTimeout = 5
  }

  geo {
    default = "src/main/resources/data/geo/test-dataset.csv"
    defaultShort = "src/main/resources/data/geo/test_short-dataset.csv"
    pathToGeo = "src/main/resources/data/geo/test-dataset.csv"
    pathToGeoShort = "src/main/resources/data/geo/test_short-dataset.csv"
  }
}

files {
  env.config = ${?envconf}
  json = "src/main/resources/data/newperiod/newPeriod.json"
  parquet = "src/main/resources/data/sample.parquet"
  links.hfile = "src/main/resources/data/links/hfile"
  enterprise.hfile = "src/main/resources/data/enterprise/hfile"
}

hbase {
  security.authentication = "kerberos"
  zookeper.url = "localhost:2181"
  files.per.region = 500
  path.config = ${?hbaseconf}  # path to hbase config resource, i.e. hbase-site.xml
  kerberos.config = ${?kerberosconf}
  table {
    links {
      name = "LINKS"
      column.family = "l"
      namespace = "ons"
    }

    enterprise {
      name = "ENT"
      column.family = "d"
      namespace = "ons"
    }

    lou {
      name = "LOU"
      column.family = "d"
      namespace = "ons"
    }

  }
}

enterprise {
  data.timeperiod = "201801"
}


